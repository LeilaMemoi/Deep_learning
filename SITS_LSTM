{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"colab":{"provenance":[],"include_colab_link":true},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":10548741,"sourceType":"datasetVersion","datasetId":6526807}],"dockerImageVersionId":30839,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"<a href=\"https://colab.research.google.com/github/LeilaMemoi/Deep_learning/blob/main/Deep_Learning_Project_Leila_Maritim.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>","metadata":{"_uuid":"d53ac206-07ec-4136-801f-ce1f77db64a2","_cell_guid":"bf63026d-b832-4885-9484-d4ff5f21cfdc","trusted":true,"collapsed":false,"id":"view-in-github","jupyter":{"outputs_hidden":false}}},{"cell_type":"markdown","source":"\n\n\n<CENTER>\n<font size=\"8\"></br>SITS FOR CROP CLASSIFICATION</font></br></div>\n</CENTER>\n<CENTER>\n\n\n<span style=\"color:blue\">Student: Maritim Leila</span>\n</CENTER>\n\n</div>","metadata":{"_uuid":"32006db6-e2a9-4ca0-bbf7-2d0c5b6c6624","_cell_guid":"de3cb3bb-84a5-4417-8956-fdd11dd7dd1f","trusted":true,"collapsed":false,"id":"t9mCseZbCAiC","jupyter":{"outputs_hidden":false}}},{"cell_type":"markdown","source":"#Introduction","metadata":{"_uuid":"fd6208a5-a401-4ee1-86a1-a09b7c8ce9d8","_cell_guid":"a16c17d9-9b3d-4352-a94c-50bc9ce4166b","trusted":true,"collapsed":false,"id":"gqYVg7-q2ZP-","jupyter":{"outputs_hidden":false}}},{"cell_type":"markdown","source":"SITS: Satellite image time series\n\nThese are a compilation of satellite images captured over an areas at distinct time intervals. The images are arranged in a three dimensional structure and each location in space and time(a pixel) corresponds to a vector of values observed across the timeline. This type of data for example is useful in classification of crop types by taking into account its phenologocial or growth variations over time.\n\nThe task at hand is a univariate time series classification. The goal is to assign a label to the entire sequence based on the temporal patterns in the bands.","metadata":{"_uuid":"f97521f1-78cf-4e45-a136-087e13938678","_cell_guid":"931fc55c-8c9d-4919-8ed4-3d26e64ce0f6","trusted":true,"collapsed":false,"id":"7XVOKHNIB9Ij","jupyter":{"outputs_hidden":false}}},{"cell_type":"code","source":"import numpy as np\nimport os\nimport datetime\nimport matplotlib.pyplot as plt\nfrom matplotlib.cm import get_cmap\nfrom textwrap import dedent\nimport torch\nimport torch.nn as nn\nfrom torch.utils.data import Dataset,TensorDataset\nfrom torchvision import datasets\nfrom torchvision.transforms import ToTensor\nfrom torchvision.transforms import transforms\nfrom torch.utils.data import DataLoader\nfrom sklearn.model_selection import train_test_split\nfrom torch.optim import lr_scheduler\nimport torch.backends.cudnn as cudnn\nfrom datetime import datetime\nfrom timeit import default_timer as timer\nimport time\nfrom tqdm.auto import tqdm\nfrom sklearn.metrics import confusion_matrix\nimport seaborn as sn\nimport torch.optim as optim\nfrom torch.optim.lr_scheduler import ReduceLROnPlateau\n\n\n\nimport torchvision.models as models","metadata":{"_uuid":"d438c37b-b676-4aa4-8bab-2768dd1e556e","_cell_guid":"792f6d92-9a43-4137-9031-e888722c7477","trusted":true,"collapsed":false,"id":"d8oJws5fhECF","jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2025-01-30T12:29:18.444392Z","iopub.execute_input":"2025-01-30T12:29:18.444730Z","iopub.status.idle":"2025-01-30T12:29:24.908971Z","shell.execute_reply.started":"2025-01-30T12:29:18.444697Z","shell.execute_reply":"2025-01-30T12:29:24.908347Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#activating CUDA\ndevice=torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\ndevice = (\n    \"cuda\"\n    if torch.cuda.is_available()\n    else \"mps\"\n    if torch.backends.mps.is_available()\n    else \"cpu\"\n)\nprint(f\"Using {device} device\")","metadata":{"_uuid":"5234ffcb-cc25-4ec4-a351-ccdd72980702","_cell_guid":"1d5273a6-03f7-43c3-8c9e-a8a2943dfbd3","trusted":true,"collapsed":false,"id":"Bm421CKXhjZA","outputId":"230980a7-eb93-4e3f-8afc-bd3ab3a328b3","jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2025-01-30T12:29:24.909678Z","iopub.execute_input":"2025-01-30T12:29:24.909967Z","iopub.status.idle":"2025-01-30T12:29:24.993399Z","shell.execute_reply.started":"2025-01-30T12:29:24.909948Z","shell.execute_reply":"2025-01-30T12:29:24.992383Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"#Data exploration\nminiTimeMatch is a modified version of TimeMatch with measurements are averaged over parcels. The original dataset covers four countires but for this study, we only consider Austria. It is a dataset made up 49168 time series with averaged reflectance valuesover the agricultural fields to obtain multivariate time series of 10 spectral bands(Sentinel 2 excluding bands 1,9, and 10)\n we average the reflectance values.Painblanc et al,(2023)\n\n Four classes were dropped to manage class imbalance and thus improve performance of the models. These classes had less than 100 samples.","metadata":{"_uuid":"5ebc0c11-361d-4fc5-8361-80ad41164cd2","_cell_guid":"61c36481-0671-4f6d-a6ea-5f3afc41c429","trusted":true,"collapsed":false,"id":"KNeKDJuy_uQu","jupyter":{"outputs_hidden":false}}},{"cell_type":"code","source":"\ndata = np.load('/kaggle/input/sits-crop-classification/data_AT1.npz', allow_pickle=True)\nseries = data['series'] # time series (m,l,d) where m is the number of time series in a given domain,\n## l is the length of the time series, and d is the number of channels in the image\nlabels = data['labels'] # label associated with each time series\ndates = data['dates'] # acquisition dates (datetime package)\nclass_names = data['class_names'] # names of the class","metadata":{"_uuid":"a772bf48-6498-4952-80cc-b29d84f72b2c","_cell_guid":"38e81ad6-dd60-49a2-a464-d931e3ae1248","trusted":true,"collapsed":false,"id":"bZurMrSwhoHK","jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2025-01-30T12:29:24.994565Z","iopub.execute_input":"2025-01-30T12:29:24.994898Z","iopub.status.idle":"2025-01-30T12:29:28.435921Z","shell.execute_reply.started":"2025-01-30T12:29:24.994865Z","shell.execute_reply":"2025-01-30T12:29:28.435055Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"print(dedent(f'''\nDataset shapes and types:\n    series: {series.shape,type(series)}\n    labels: {labels.shape,type(labels)}\n    dates: {dates.shape,type(dates)}\n    class:{class_names.shape,type(class_names)}\n'''))","metadata":{"_uuid":"e7a8d094-cb9b-4963-9a2e-e9b39784ae26","_cell_guid":"ebad4591-3736-4cf8-8aa4-4abf125c066b","trusted":true,"collapsed":false,"id":"HgXiGBRamxo-","outputId":"a8df7c53-9184-4595-da7e-0e4a841e09e3","jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2025-01-30T12:29:28.436782Z","iopub.execute_input":"2025-01-30T12:29:28.437072Z","iopub.status.idle":"2025-01-30T12:29:28.442360Z","shell.execute_reply.started":"2025-01-30T12:29:28.437046Z","shell.execute_reply":"2025-01-30T12:29:28.441474Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## class distribution","metadata":{"_uuid":"702a3d82-67bc-471c-a2fb-56f4db9c7e9f","_cell_guid":"0fad4015-55bf-41bc-88a4-aec425960cda","trusted":true,"collapsed":false,"id":"UdOMv3WQAD9o","jupyter":{"outputs_hidden":false}}},{"cell_type":"code","source":"\n\n#To visualize the distribution of classes\ndef classFrequency(labels,colormap,class_names,scale=True):\n  unique_labels, label_counts = np.unique(labels, return_counts=True)\n\n  #colormap\n  cmap = plt.get_cmap(colormap)  #'tab20' for 17classes\n\n  # Plotting class frequencies\n  fig, ax = plt.subplots()\n  if scale:\n    bars = ax.bar(class_names, np.log(label_counts), color=[cmap(i) for i in range(len(class_names))])\n  else:\n    bars = ax.bar(class_names, label_counts, color=[cmap(i) for i in range(len(class_names))])\n\n\n  legend_labels = [f'Class {label}: {class_name}' for label, class_name in zip(unique_labels, class_names)]\n  ax.legend(bars, legend_labels, loc='upper left', bbox_to_anchor=(1, 1))\n  plt.xlabel('Class ')\n  plt.ylabel('Count(Log scale)')\n  plt.title('Class Frequencies')\n\n  # Rotate x-axis labels for better readability\n  plt.xticks(rotation=45, ha='right')\n\n  plt.show()","metadata":{"_uuid":"146d8edf-a5cc-4c08-9fc5-4151af392c98","_cell_guid":"e360a4b3-74a7-4a81-8cfe-f9ced54cf266","trusted":true,"collapsed":false,"id":"N9ulraOJnpzQ","jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2025-01-30T12:29:28.443074Z","iopub.execute_input":"2025-01-30T12:29:28.443314Z","iopub.status.idle":"2025-01-30T12:29:28.462078Z","shell.execute_reply.started":"2025-01-30T12:29:28.443292Z","shell.execute_reply":"2025-01-30T12:29:28.461225Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Calculate class frequencies\nimport pandas as pd\ndef label_count(label, name):\n    unique_labels, label_counts = np.unique(label, return_counts=True)\n    counts_df = pd.DataFrame({'Class': unique_labels, f'Count_{name}': label_counts})\n    return counts_df\n\ncounts_data = label_count(labels,'class_distribution')\nprint(counts_data)","metadata":{"_uuid":"5f13d061-0fdb-465a-8fa9-bc66c4a55faa","_cell_guid":"8d497432-ddb0-47d0-a259-af296ef06ef6","trusted":true,"collapsed":false,"id":"8N-JzcFuUulJ","outputId":"6ffcb310-6c0c-4878-d206-5b34ff10e208","jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2025-01-30T12:29:28.464659Z","iopub.execute_input":"2025-01-30T12:29:28.464919Z","iopub.status.idle":"2025-01-30T12:29:28.498228Z","shell.execute_reply.started":"2025-01-30T12:29:28.464897Z","shell.execute_reply":"2025-01-30T12:29:28.497483Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#in the whole dataset\nclassFrequency(labels,'tab20',class_names,scale=False)\n\n\nplt.tight_layout()\nplt.show()","metadata":{"_uuid":"d15d1046-7011-408d-a7d8-3d99fc88418c","_cell_guid":"d9bf12bb-3841-454c-9e8c-1e80e3b6bf04","trusted":true,"collapsed":false,"id":"NnIg_Ha1RRoU","outputId":"a17ba007-0455-455c-9292-21cdcb24788d","jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2025-01-30T12:29:28.499566Z","iopub.execute_input":"2025-01-30T12:29:28.499774Z","iopub.status.idle":"2025-01-30T12:29:28.934445Z","shell.execute_reply.started":"2025-01-30T12:29:28.499756Z","shell.execute_reply":"2025-01-30T12:29:28.933505Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"The plot above (fig 1)shows class distribution in the dataset. We note some imbalance in class distribution. Five classes in particular, spring peas, spring rapeseed,spring rye,spring triticale,spring wheat and sunflowers have a much smaller count compared to the rest of the classes(less than 100). This would affect the splitting of the dataset as there might not be sufficient samples to have the data in each of the splits. Furthermore, the models may not perform well predicting these classes. Therfore, it is necessary to drop these classes.\n\nFor improved visualization, we use the log scale(fig 2)","metadata":{"_uuid":"1bae9bf7-359b-4bb4-badb-348fc4ee9a72","_cell_guid":"8adfd4b0-51f0-4b57-b0fe-7975a7fd8c3f","trusted":true,"collapsed":false,"id":"TBBG35E9ANtu","jupyter":{"outputs_hidden":false}}},{"cell_type":"code","source":"#in the whole dataset\nclassFrequency(labels,'tab20',class_names,scale=True)\n\n\nplt.tight_layout()\nplt.show()","metadata":{"_uuid":"5d189b5b-3729-409f-b194-c11b600b44f5","_cell_guid":"c60000a1-7cd2-49c9-a439-b8a612cc3186","trusted":true,"collapsed":false,"id":"RUFb_szYUNUx","outputId":"6950f4bc-6976-4cea-e240-240088347dc1","jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2025-01-30T12:29:28.935464Z","iopub.execute_input":"2025-01-30T12:29:28.935774Z","iopub.status.idle":"2025-01-30T12:29:29.273082Z","shell.execute_reply.started":"2025-01-30T12:29:28.935743Z","shell.execute_reply":"2025-01-30T12:29:29.272367Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### class drops","metadata":{"_uuid":"a1e73efe-c8e2-47e3-8828-e22af7e822ea","_cell_guid":"0c673cce-62bf-4767-9ae6-29e714443ba3","trusted":true,"collapsed":false,"id":"cf2fxeSFAX42","jupyter":{"outputs_hidden":false}}},{"cell_type":"code","source":"import numpy as np\ndef class_drop(X,y):\n  # Count the occurrences of each class in the training set\n  unique_labels, class_counts = np.unique(y, return_counts=True)\n\n  # Set a threshold for the minimum number of samples per class\n  min_samples_per_class = 100\n\n  # Find classes with fewer samples than the threshold\n  classes_to_drop = np.where(class_counts < min_samples_per_class)[0]\n\n  # Print the classes to be dropped\n  print(\"Classes to be dropped:\", classes_to_drop)\n\n  # Filter out samples belonging to the identified classes from the data\n  mask_train = np.isin(y, classes_to_drop, invert=True)\n\n\n  X_filtered = X[mask_train]\n  y_filtered = y[mask_train]\n\n  return X_filtered,y_filtered","metadata":{"_uuid":"b4812d8c-5d8c-42f8-8464-6c8bc75ecc1f","_cell_guid":"3fb5162a-d1a7-4d92-b21c-bc1a9616b1bf","trusted":true,"collapsed":false,"id":"QFFHspbtSta0","jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2025-01-30T12:29:29.273909Z","iopub.execute_input":"2025-01-30T12:29:29.274274Z","iopub.status.idle":"2025-01-30T12:29:29.278654Z","shell.execute_reply.started":"2025-01-30T12:29:29.274244Z","shell.execute_reply":"2025-01-30T12:29:29.278031Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"X,y=class_drop(series,labels)","metadata":{"_uuid":"ad94ac0f-3ad8-41be-8597-bea8ce936529","_cell_guid":"59fa288c-b6a3-4d12-a970-8e44a661fd93","trusted":true,"collapsed":false,"id":"hwf65b7nTIN5","outputId":"f7950981-c612-421e-8ccf-fe6556722beb","jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2025-01-30T12:29:29.279498Z","iopub.execute_input":"2025-01-30T12:29:29.279741Z","iopub.status.idle":"2025-01-30T12:29:29.367577Z","shell.execute_reply.started":"2025-01-30T12:29:29.279715Z","shell.execute_reply":"2025-01-30T12:29:29.366682Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"classes_to_drop = ['spring_peas','spring_rye', 'spring_rapeseed','spring_triticale','spring_wheat','sunflowers']\n\n# Drop the specified classes\nclass_names_filtered = class_names[~np.isin(class_names, classes_to_drop)]\nprint(class_names_filtered)","metadata":{"_uuid":"7a284bbf-f43d-4d9a-8a23-d392ab7614af","_cell_guid":"3f7ed0a7-aa0c-4cda-8da9-17aef897bb42","trusted":true,"collapsed":false,"id":"KFxUOvILcHdn","outputId":"65cdf047-6ecb-4db4-b84d-e940c6308bee","jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2025-01-30T12:29:29.368641Z","iopub.execute_input":"2025-01-30T12:29:29.368968Z","iopub.status.idle":"2025-01-30T12:29:29.373882Z","shell.execute_reply.started":"2025-01-30T12:29:29.368936Z","shell.execute_reply":"2025-01-30T12:29:29.372930Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"With the dropped classes, we have to adjust the labels to have a consecutive order to avoid potential issues arising in subsequent algorithms and libraries and to also have a standard convention","metadata":{"_uuid":"4bb00c90-8ab4-4e54-8aee-37962a076185","_cell_guid":"76b193e2-786b-4104-83ce-51d8d0ae1463","trusted":true,"collapsed":false,"id":"Tz8iO_e4aIog","jupyter":{"outputs_hidden":false}}},{"cell_type":"code","source":"unique_labels = np.unique(y)\n\n# Create a mapping from old labels to new consecutive labels\nlabel_mapping = {old_label: new_label for new_label, old_label in enumerate(unique_labels)}\n\n# Update labels using the mapping\ny = np.array([label_mapping[label] for label in y])","metadata":{"_uuid":"4bfda256-658e-44ee-8d3d-14944ad15a26","_cell_guid":"466d61b6-11a3-44e3-be3f-e6b6b3b1a3e5","trusted":true,"collapsed":false,"id":"cd7v4JYMddWZ","jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2025-01-30T12:29:29.374937Z","iopub.execute_input":"2025-01-30T12:29:29.375273Z","iopub.status.idle":"2025-01-30T12:29:29.402428Z","shell.execute_reply.started":"2025-01-30T12:29:29.375245Z","shell.execute_reply":"2025-01-30T12:29:29.401848Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"counts_data = label_count(y,'class_distribution')\nprint(counts_data)","metadata":{"_uuid":"73eb6e2d-7199-415b-8bf8-3f2ae33281e2","_cell_guid":"4eb5d0cf-b1b2-4f9f-be76-f30bb52a3c74","trusted":true,"collapsed":false,"id":"8SPA6WpskzJO","outputId":"5709fcf6-90fe-4ef0-9630-bef6d0c74132","jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2025-01-30T12:29:29.403073Z","iopub.execute_input":"2025-01-30T12:29:29.403270Z","iopub.status.idle":"2025-01-30T12:29:29.410127Z","shell.execute_reply.started":"2025-01-30T12:29:29.403253Z","shell.execute_reply":"2025-01-30T12:29:29.409345Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"##descriptive statistics","metadata":{"_uuid":"537e83cc-1942-48af-84ae-8d5ccaf6b1df","_cell_guid":"1d94a724-196c-43ba-ba42-ca4fae699a69","trusted":true,"collapsed":false,"id":"eq-nefEAlurj","jupyter":{"outputs_hidden":false}}},{"cell_type":"code","source":"#mean for each crop types across the timeline\nclass_means = {}\nfor class_name in np.unique(class_names_filtered):\n    class_indices = np.where(class_names_filtered == class_name)[0]\n    class_data = series[class_indices]\n    mean_across_time = np.mean(class_data, axis=(0, 2))  # Calculate mean across time and channels\n    class_means[class_name] = mean_across_time\n\n# Plot the mean for each class in separate subplots with different colors\nnum_classes = len(class_means)\nfig, axes = plt.subplots(num_classes, 1, figsize=(12, 4 * num_classes), sharex=True)\n\n# Define a set of distinct colors for each class\ncolors = plt.get_cmap('tab10', num_classes)\n\nfor i, (class_name, mean_across_time) in enumerate(class_means.items()):\n    color = colors(i)\n    axes[i].plot(dates, mean_across_time, color=color, label=f'Class {class_name}')\n    axes[i].set_ylabel('Mean Value ')\n\n    axes[i].legend()\n\nplt.xlabel('Timeline')\nplt.suptitle('Temporal patterns for each crop type', y=0.92)\n\nplt.show()","metadata":{"_uuid":"8b9e6540-d2cf-4de9-bbca-49786923c24f","_cell_guid":"443e6c70-9194-4237-a535-8b215732b76c","trusted":true,"collapsed":false,"id":"6EVONMsYhdj3","outputId":"8221809a-b89f-4826-f58f-2704a029c88f","jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2025-01-30T12:29:29.410958Z","iopub.execute_input":"2025-01-30T12:29:29.411256Z","iopub.status.idle":"2025-01-30T12:29:32.079676Z","shell.execute_reply.started":"2025-01-30T12:29:29.411230Z","shell.execute_reply":"2025-01-30T12:29:32.078820Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"The mean reflectance plots above show distinct and subtle fluctuations over time which would be an indication of variations in vegetation growth or phenological changes for different crop types. The classifiers should ideally use these patterns to determine the time series class.","metadata":{"_uuid":"f4ab8743-dd2f-49a9-b72f-4f9c444465d5","_cell_guid":"f239b2f5-ef94-4ff4-9274-b6ddfda676d8","trusted":true,"collapsed":false,"id":"hDw482M_eFSx","jupyter":{"outputs_hidden":false}}},{"cell_type":"markdown","source":"#Data preparation","metadata":{"_uuid":"ba94292d-cfdd-4b94-88ea-711a2bb25639","_cell_guid":"b11a7279-f7ea-4316-8945-718d68836a1c","trusted":true,"collapsed":false,"id":"ByDHeg192txb","jupyter":{"outputs_hidden":false}}},{"cell_type":"markdown","source":"##Custom dataset\n\nDataloaders : torch Dataloader takes a torch Dataset as input, and calls the __getitem__() function from the Dataset class to create a batch of data.\n\nThis class organizes the time series data into suitable formats, allowing for customizable transform parameters depending on the specific preprocessing needed.\n\nFor one method employed, flattening and normalization is applied while in another, only normalization is required. Normalization was applied to stabilize training and improve convergence.","metadata":{"_uuid":"61055580-f330-4658-b285-bb7462b98564","_cell_guid":"0f52b983-4516-4499-b344-0b0ae9f70613","trusted":true,"collapsed":false,"id":"KV7GYi7P2xui","jupyter":{"outputs_hidden":false}}},{"cell_type":"code","source":"class TimeSeriesDataset(Dataset):\n\n  def __init__(self, x, y,transform=None):\n    self.x=x\n    self.y=y\n    self.transform=transform  #optional transforms\n\n\n\n  def __len__(self):\n    return len(self.x)\n\n  def __getitem__(self, idx):\n\n    features=self.x[idx]\n    target=self.y[idx]\n\n    if self.transform:\n        features=self.transform(features)\n\n    #Convert to tensors\n    features=torch.tensor(features,dtype=torch.float32)\n    target=torch.tensor(target,dtype=torch.long)\n\n\n    return features,target","metadata":{"_uuid":"252e6920-44bc-4045-9e54-8539e07105f4","_cell_guid":"8362b93a-0ca5-4f13-8118-f0fffef8973d","trusted":true,"collapsed":false,"id":"h7Gg5XQNu-Qg","jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2025-01-30T12:29:32.080417Z","iopub.execute_input":"2025-01-30T12:29:32.080612Z","iopub.status.idle":"2025-01-30T12:29:32.085490Z","shell.execute_reply.started":"2025-01-30T12:29:32.080595Z","shell.execute_reply":"2025-01-30T12:29:32.084735Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"##transforms\n\nCustom min_max normalization\n\nCommon standardization techniques like z_normalization are not appropriate for vegetation mapping as they do not capture the significance of NDVI magnitudes which is essential in mapping. The traditional min0max normalization on the other hand is sensitive to extreme values. As a result, rather than the max and min, we substitute with the 2% and 98 % percentile instead. Pelletier et al,(2019)","metadata":{"_uuid":"a82f9dad-699e-44c9-a89c-da020dbe009d","_cell_guid":"b1241183-f6fb-46e4-9b21-59ede5638717","trusted":true,"collapsed":false,"id":"A39nt39z3Onq","jupyter":{"outputs_hidden":false}}},{"cell_type":"code","source":"#transforms\n\n\nclass NormalizeTransform(): #a custom normalization that uses the 2nd and 98th percentile as min and max values respectively\n    def __init__(self, min, max):\n        self.min = min\n        self.max = max\n\n    def __call__(self, sample):\n\n        sample=(sample - self.min) / (self.max-self.min)\n        return sample\n\n\nclass Transpose():# to change the shape (m,d,l) where m is the number of time series in a given domain,\n## l is the length of the time series, and d is the number of channels in the image\n  def __call__(self,sample):\n    sample=sample.transpose(1,0)\n    return sample","metadata":{"_uuid":"faaa2c81-06b8-4dcd-8e46-4cfe3bf73775","_cell_guid":"f937fb06-f1ad-4320-9f7e-327f316e5dab","trusted":true,"collapsed":false,"id":"iVy-zfNTlK-z","jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2025-01-30T12:29:32.086447Z","iopub.execute_input":"2025-01-30T12:29:32.086660Z","iopub.status.idle":"2025-01-30T12:29:32.101181Z","shell.execute_reply.started":"2025-01-30T12:29:32.086644Z","shell.execute_reply":"2025-01-30T12:29:32.100492Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"\n## Data Splitting for Training and Testing\n\nIn our dataset, we aim to ensure that each class is well-represented in the training, validation and testing datasets. To achieve this, we will use the `StratifiedShuffleSplit` method from scikit-learn with the following split ratios:\n\n- **Training Set**: 85%\n- **Validation Set**: 7.5%\n- **Testing Set**: 7.5%","metadata":{"_uuid":"1c1b449b-bc6f-436c-9ec6-ffee728f869f","_cell_guid":"c4365af6-1b49-4204-af48-df0135dd9959","trusted":true,"collapsed":false,"id":"9zZJLM8VTCj8","jupyter":{"outputs_hidden":false}}},{"cell_type":"code","source":"#initial split of the data for computing min and max values\nseed = 42\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.15, random_state=seed, shuffle=True,stratify=y)\nX_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.15, random_state=seed, shuffle=True,stratify=y_train)","metadata":{"_uuid":"0f91e0f1-ad5c-449f-9ecf-359db5d6f748","_cell_guid":"b8c7c1bb-f11e-4433-9c66-45c33ef0241a","trusted":true,"collapsed":false,"id":"Lm8vA82TkJbD","jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2025-01-30T12:29:32.101783Z","iopub.execute_input":"2025-01-30T12:29:32.101963Z","iopub.status.idle":"2025-01-30T12:29:32.285522Z","shell.execute_reply.started":"2025-01-30T12:29:32.101947Z","shell.execute_reply":"2025-01-30T12:29:32.284816Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"X_val.shape","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-30T12:29:32.286437Z","iopub.execute_input":"2025-01-30T12:29:32.286729Z","iopub.status.idle":"2025-01-30T12:29:32.291732Z","shell.execute_reply.started":"2025-01-30T12:29:32.286699Z","shell.execute_reply":"2025-01-30T12:29:32.291147Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#compute min and max values to be used in normalization\nmin_per=np.percentile(X_train,2,axis=0)\nmax_per=np.percentile(X_train,98,axis=0)","metadata":{"_uuid":"d0400efc-c0a6-4e81-8edb-67912723663f","_cell_guid":"36fa5cbf-a0a6-4865-af43-cf6582570f13","trusted":true,"collapsed":false,"id":"vwr_BWoeC-CW","jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2025-01-30T12:29:32.292430Z","iopub.execute_input":"2025-01-30T12:29:32.292649Z","iopub.status.idle":"2025-01-30T12:29:33.311302Z","shell.execute_reply.started":"2025-01-30T12:29:32.292627Z","shell.execute_reply":"2025-01-30T12:29:33.310367Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"The distribution of classes in the split data","metadata":{"_uuid":"1425c473-360d-42c2-a68a-f7092c499247","_cell_guid":"09fc39e6-c9a0-4f19-a778-4f525e822d96","trusted":true,"collapsed":false,"id":"HIAaWon1F9Qm","jupyter":{"outputs_hidden":false}}},{"cell_type":"code","source":"#class distribution in the data splits\ncounts_train = label_count(y_train, 'Train')\ncounts_val = label_count(y_val, 'Val')\ncounts_test = label_count(y_test, 'Test')\n\n# Merge the counts into a single table\nmerged_counts = pd.merge(counts_train, counts_val, on='Class', how='outer')\nmerged_counts = pd.merge(merged_counts, counts_test, on='Class', how='outer')\n\n# Print the table\nprint(merged_counts)","metadata":{"_uuid":"26018303-707e-4c25-b7d8-ef3f44e4a9e2","_cell_guid":"f801c53f-190c-48d3-8b49-249938d5ae90","trusted":true,"collapsed":false,"id":"Tv_a7U31E35s","outputId":"d12a8a6a-d8a3-4ceb-b6f6-71126c5a090e","jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2025-01-30T12:29:33.315284Z","iopub.execute_input":"2025-01-30T12:29:33.315527Z","iopub.status.idle":"2025-01-30T12:29:33.332997Z","shell.execute_reply.started":"2025-01-30T12:29:33.315508Z","shell.execute_reply":"2025-01-30T12:29:33.332390Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Meadow has a significantly large representation","metadata":{"_uuid":"90750c6f-aaf9-4ba6-8019-cee08d8fed23","_cell_guid":"9585c477-bb2f-406f-82c5-dd6ea3fe1b7a","trusted":true,"collapsed":false,"id":"_FmxQw0NgEaJ","jupyter":{"outputs_hidden":false}}},{"cell_type":"code","source":"feature_transform = transforms.Compose([NormalizeTransform(min_per,max_per)])\ntrain_dataset=TimeSeriesDataset(X_train,y_train,transform=feature_transform)\nval_dataset=TimeSeriesDataset(X_train,y_train,transform=feature_transform)\ntest_dataset=TimeSeriesDataset(X_train,y_train,transform=feature_transform)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-30T12:29:33.334320Z","iopub.execute_input":"2025-01-30T12:29:33.334514Z","iopub.status.idle":"2025-01-30T12:29:33.339604Z","shell.execute_reply.started":"2025-01-30T12:29:33.334497Z","shell.execute_reply":"2025-01-30T12:29:33.338960Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"torch.manual_seed(seed)\nbatch_size=128\ntrain_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\nval_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=True)\ntest_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=True)\n#dataset_sizes = {'train': len(train_dataset), 'val': len(val_dataset), 'test': len(test_dataset)}","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-30T12:29:33.340311Z","iopub.execute_input":"2025-01-30T12:29:33.340567Z","iopub.status.idle":"2025-01-30T12:29:33.357642Z","shell.execute_reply.started":"2025-01-30T12:29:33.340535Z","shell.execute_reply":"2025-01-30T12:29:33.356952Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Check the shape of one batch\nfor X_batch, y_batch in train_loader:\n    print(\"Batch series shape:\", X_batch.shape) \n    print(\"Batch labels shape:\", y_batch.shape)  \n    break","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-30T12:29:33.358285Z","iopub.execute_input":"2025-01-30T12:29:33.358470Z","iopub.status.idle":"2025-01-30T12:29:33.435576Z","shell.execute_reply.started":"2025-01-30T12:29:33.358454Z","shell.execute_reply":"2025-01-30T12:29:33.434965Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"class LSTMModel(nn.Module):\n    def __init__(self, input_size, hidden_size, output_size, num_layers, dropout):\n        super(LSTMModel, self).__init__()\n        self.lstm = nn.LSTM(input_size, hidden_size, num_layers, batch_first=True, dropout=dropout)\n        self.fc = nn.Linear(hidden_size, output_size)\n        #self.softmax = nn.Softmax(dim=1)\n\n    def forward(self, x):\n        # x: (batch_size, sequence_length, input_size)\n        #x = x.transpose(1, 2)\n        out, (h_n, c_n) = self.lstm(x)  # LSTM output\n        # Take the last hidden state\n        out = h_n[-1]  # Shape: (batch_size, hidden_size)\n        logits = self.fc(out)  # Shape: (batch_size, output_size)\n        #return self.softmax(logits)\n        return logits\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-30T12:29:33.436279Z","iopub.execute_input":"2025-01-30T12:29:33.436548Z","iopub.status.idle":"2025-01-30T12:29:33.441569Z","shell.execute_reply.started":"2025-01-30T12:29:33.436522Z","shell.execute_reply":"2025-01-30T12:29:33.440822Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Training,evaluation and plotting functions","metadata":{"_uuid":"b82af6a4-90e0-43ee-bfce-d01a0a61b6e5","_cell_guid":"4a5dd1d8-e4bb-4af6-94cd-7e379cba0e5f","trusted":true,"collapsed":false,"id":"CZPKA9n3bwo4","jupyter":{"outputs_hidden":false}}},{"cell_type":"code","source":"import torch\nfrom torch.utils.tensorboard import SummaryWriter\nfrom sklearn.metrics import classification_report, confusion_matrix\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom timeit import default_timer as timer\nfrom tqdm import tqdm\nimport numpy as np\n\n# Define the train_model function\ndef train_model():\n    best_val_loss = float('inf')\n    patience = 5\n    no_improvement_counter = 0\n\n    try:\n        for epoch in range(epochs):\n            print(f'EPOCH {epoch + 1}:')\n            start_time = timer()\n            train_loss = 0.0\n            correct_predictions = 0\n            total_samples = 0\n\n            model.train()\n            for X_trbatch, y_trbatch in tqdm(train_loader):\n                X_trbatch = X_trbatch.to(device)\n                y_trbatch =  y_trbatch.to(device)\n\n                # Forward pass\n                y_hat = model(X_trbatch)\n\n                # Compute the loss\n                loss = criterion(y_hat, y_trbatch)\n                train_loss += loss.item()\n\n                # Backward pass and optimization step\n                optimizer.zero_grad()\n                loss.backward()\n                optimizer.step()\n\n                # Count correct predictions\n                _, predicted = torch.max(y_hat, 1)\n                correct_predictions += (predicted == y_trbatch).sum().item()\n                total_samples += y_trbatch.size(0)\n\n            # Calculate accuracy and average loss for training\n            train_accuracy = correct_predictions / total_samples\n            train_average_loss = train_loss / total_samples\n\n            # Log training loss and accuracy to TensorBoard\n            writer.add_scalar('lr', optimizer.param_groups[0]['lr'], epoch + 1)\n            writer.add_scalar('loss/train', train_average_loss, epoch + 1)\n            writer.add_scalar('acc/train', train_accuracy, epoch + 1)\n\n            # Validation\n            model.eval()\n            valid_loss = 0.0\n            correct_predictions_val = 0\n            total_samples_val = 0\n\n            with torch.no_grad():\n                for X_vbatch, y_vbatch in tqdm(val_loader):\n                    X_vbatch = X_vbatch.to(device)\n                    y_vbatch =  y_vbatch.to(device)\n\n                    y_val_hat = model(X_vbatch)\n\n                    val_loss = criterion(y_val_hat, y_vbatch)\n                    valid_loss += val_loss.item()\n\n                    _, predicted_val = torch.max(y_val_hat, 1)\n                    correct_predictions_val += (predicted_val == y_vbatch).sum().item()\n                    total_samples_val += y_vbatch.size(0)\n\n                scheduler.step(valid_loss)\n\n                # Calculate accuracy and average loss for validation\n                val_accuracy = correct_predictions_val / total_samples_val\n                val_average_loss = valid_loss / total_samples_val\n\n                # Log validation loss and accuracy to TensorBoard\n                writer.add_scalar('loss/val', val_average_loss, epoch + 1)\n                writer.add_scalar('acc/val', val_accuracy, epoch + 1)\n\n            print(f'LOSS train {train_average_loss}, valid {val_average_loss}')\n            print(f'ACCURACY train {train_accuracy}, valid {val_accuracy}')\n\n            # Early stopping\n            if val_average_loss < best_val_loss:\n                best_val_loss = val_average_loss\n                no_improvement_counter = 0\n                # Save the current best model\n                best_model_path = f'./LSTM_model_lr_{lr}.pth'\n                torch.save({'epoch': epoch,\n                            'model_state': model.state_dict(),\n                            'optimizer_state_dict': optimizer.state_dict()}, best_model_path)\n            else:\n                no_improvement_counter += 1\n\n            if patience is not None and no_improvement_counter >= patience:\n                print(f\"No improvement for {patience} epochs. Early stopping...\")\n                break\n\n            end_time = timer()\n            print(f\"Epoch {epoch + 1} completed. Total epoch time: {end_time - start_time:.3f} seconds\")\n\n    except Exception as e:\n        print(f\"An error occurred: {e}\")\n\n","metadata":{"_uuid":"615f4cae-a29b-4751-8e45-cfda9959afe1","_cell_guid":"e81f7dd4-5198-408f-93b7-20abce4eaa4e","trusted":true,"collapsed":false,"id":"XdzLHYw2vXWf","jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2025-01-30T12:29:33.442389Z","iopub.execute_input":"2025-01-30T12:29:33.442692Z","iopub.status.idle":"2025-01-30T12:29:45.064737Z","shell.execute_reply.started":"2025-01-30T12:29:33.442665Z","shell.execute_reply":"2025-01-30T12:29:45.064088Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Hyperparameters\nnum_channels = 10  # 10 bands\nnum_classes=len(class_names_filtered)\ninput_size = num_channels  # Number of features\nhidden_size = 64  # Number of hidden units\noutput_size = num_classes  # Number of classes\nnum_layers = 2  # Number of LSTM layers\ndropout = 0.3  # Dropout rate\nepochs=30\nlr=0.001\nexperiment = f'epochs_{epochs}_batch_size_{batch_size}_CNN_lr_{lr}'\nlog_dir = f'_{experiment}'\nwriter = SummaryWriter(comment=log_dir)\n# Instantiate the model\nmodel = LSTMModel(input_size, hidden_size, output_size, num_layers, dropout).to(device)\n\n# Define loss function and optimizer\ncriterion = nn.CrossEntropyLoss()\noptimizer = optim.Adam(model.parameters(), lr=lr)\nscheduler = ReduceLROnPlateau(optimizer, mode='min')\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-30T12:29:45.065632Z","iopub.execute_input":"2025-01-30T12:29:45.066276Z","iopub.status.idle":"2025-01-30T12:29:45.351170Z","shell.execute_reply.started":"2025-01-30T12:29:45.066245Z","shell.execute_reply":"2025-01-30T12:29:45.350479Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Call the train_model function\ntrain_model()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-30T12:29:45.351916Z","iopub.execute_input":"2025-01-30T12:29:45.352164Z","iopub.status.idle":"2025-01-30T12:31:15.722094Z","shell.execute_reply.started":"2025-01-30T12:29:45.352143Z","shell.execute_reply":"2025-01-30T12:31:15.721299Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Define the test_model function\ndef test_model():\n    # Load the best saved model\n    checkpoint = torch.load(f'./LSTM_model_lr_{lr}.pth',map_location=torch.device('cpu'))\n    model.load_state_dict(checkpoint['model_state'])\n    model.eval()\n\n    all_true_labels = []\n    all_predicted_labels = []\n    cum_test_loss = 0.0\n    correct_predictions_test = 0\n    total_samples_test = 0\n\n    with torch.no_grad():\n        for X_testbatch, y_testbatch in tqdm(test_loader):\n            X_testbatch = X_testbatch.to(device)\n            y_testbatch =  y_testbatch.to(device)\n\n            y_test_hat = model(X_testbatch)\n\n            test_loss = criterion(y_test_hat, y_testbatch)\n            cum_test_loss += test_loss.item()\n\n            _, predicted_test = torch.max(y_test_hat, 1)\n            correct_predictions_test += (predicted_test == y_testbatch).sum().item()\n            total_samples_test += y_testbatch.size(0)\n\n            # Collect all true labels and predictions\n            all_true_labels.extend(y_testbatch.cpu().numpy())\n            all_predicted_labels.extend(predicted_test.cpu().numpy())\n\n        # Calculate accuracy and average loss for testing\n        test_accuracy = correct_predictions_test / total_samples_test\n        test_average_loss = cum_test_loss / total_samples_test\n\n        # Log test loss and accuracy to TensorBoard\n        #writer.add_scalar('loss/test', test_average_loss, epoch + 1)\n       # writer.add_scalar('acc/test', test_accuracy, epoch + 1)\n\n    print(f'LOSS test {test_average_loss}')\n    print(f'ACCURACY test {test_accuracy}')\n\n    # # Generate classification report and confusion matrix\n    # all_true_labels = np.array(all_true_labels)\n    # all_predicted_labels = np.array(all_predicted_labels)\n    # class_names = ['Imp_Surf', 'Bldgs', 'Low_Veg', 'Tree', 'Car', 'Clutter']\n\n    # # Generate classification report\n    # class_report = classification_report(all_true_labels, all_predicted_labels, target_names=class_names, zero_division=0)\n    # print(\"Classification Report:\\n\", class_report)\n\n    # # Generate confusion matrix\n    # conf_matrix = confusion_matrix(all_true_labels, all_predicted_labels)\n\n    # # Plot confusion matrix\n    # fig, ax = plt.subplots(figsize=(10, 8))\n    # sns.heatmap(conf_matrix, annot=True, fmt=\"d\", cmap=\"Blues\", xticklabels=class_names, yticklabels=class_names)\n    # ax.set_xlabel('Predicted Labels')\n    # ax.set_ylabel('True Labels')\n    # ax.set_title('Confusion Matrix')\n    # plt.show()\n\n    # # Optionally log classification report and confusion matrix to TensorBoard\n    # writer.add_text('Classification Report', class_report)\n    # fig_conf_matrix = plt.figure(figsize=(10, 8))\n    # sns.heatmap(conf_matrix, annot=True, fmt=\"d\", cmap=\"Blues\", xticklabels=class_names, yticklabels=class_names)\n    # plt.xlabel('Predicted Labels')\n    # plt.ylabel('True Labels')\n    # plt.title('Confusion Matrix')\n    # writer.add_figure('Confusion Matrix', fig_conf_matrix)\n    # plt.close(fig_conf_matrix)\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-30T12:31:15.722821Z","iopub.execute_input":"2025-01-30T12:31:15.723091Z","iopub.status.idle":"2025-01-30T12:31:15.729423Z","shell.execute_reply.started":"2025-01-30T12:31:15.723071Z","shell.execute_reply":"2025-01-30T12:31:15.728590Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Call the test_model function\ntest_model()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-30T12:31:15.730093Z","iopub.execute_input":"2025-01-30T12:31:15.730284Z","iopub.status.idle":"2025-01-30T12:31:17.015403Z","shell.execute_reply.started":"2025-01-30T12:31:15.730267Z","shell.execute_reply":"2025-01-30T12:31:17.014583Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# References\n\n1. Pelletier, C., Webb, G., & Petitjean, F. (2019). Temporal Convolutional Neural Network for the Classification of Satellite Image Time Series. Remote Sensing, 11(5), 523. https://doi.org/10.3390/rs11050523\n\n2. Painblanc, F., Chapel, L., Courty, N., Friguet, C., Pelletier, C., & Tavenard, R. (2023). Match-And-Deform: Time Series Domain Adaptation Through Optimal Transport and Temporal Alignment. In D. Koutra, C. Plant, M. Gomez Rodriguez, E. Baralis, & F. Bonchi (Eds.), Machine Learning and Knowledge Discovery in Databases: Research Track (Vol. 14173, pp. 341–356). Springer Nature Switzerland. https://doi.org/10.1007/978-3-031-43424-2_21\n\n\n3. [batch-norm-explained](https://towardsdatascience.com/batch-norm-explained-visually-how-it-works-and-why-neural-networks-need-it-b18919692739)","metadata":{"_uuid":"7dc8bd7d-e266-47c5-ba27-9e7d287fbfa0","_cell_guid":"2b328456-7a0e-415e-b450-b4b1617367a9","trusted":true,"collapsed":false,"id":"uu__M7MAnRDc","jupyter":{"outputs_hidden":false}}}]}